{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa5b7771",
   "metadata": {},
   "source": [
    "# Monai Tutorial Notebook\n",
    "\n",
    "In this notebook we copied part of Monai's tutorial code from here: https://github.com/Project-MONAI/tutorials/blob/master/modules/TorchIO_MONAI_PyTorch_Lightning.ipynb to build a small CNN for 3D images. For dataloading torchio is used which seems to be faster than the other dataloading libraries (niblabel, simpleitk) which was shown in the nifty data exploration notebook in ../notebooks/0_eda/. In the \"MRIDataModule\" preprocessing techniques can be defined. Currently, the files are too big for big computations, so they are resized. The training loop is managed by Pytorch Lightning which offers clearer building blocks to start the training or validation loops. To build the models we use Sequential Pytorch model blocks but Monai also offers some very advanced neural network blocks as well. They are all featured in the Monai Documentation:\n",
    "\n",
    "https://docs.monai.io/en/stable/highlights.html#network-architectures and\n",
    "\n",
    "https://docs.monai.io/en/stable/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bbcd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, Sampler\n",
    "\n",
    "sys.path.insert(0, '../../models/')\n",
    "sys.path.insert(0, '../../scripts/')\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "\n",
    "from helpers import miscellaneous as misc\n",
    "from helpers import plotters\n",
    "from helpers import preprocessing\n",
    "CONFIG = misc.get_config()\n",
    "\n",
    "from ModelUtils import EncoderCNN\n",
    "from ModelUtils import CognitiveTestMLP\n",
    "from ModelUtils import FusionModel\n",
    "\n",
    "#get Loader.py\n",
    "from Loader import MRIDataset\n",
    "\n",
    "#get TrainUtils.py helpers\n",
    "from TrainUtils import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3960107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, task, batch_size, data_paths, include_preprocess = False, include_augment = False):\n",
    "        super().__init__()\n",
    "        self.task = task\n",
    "        self.batch_size = batch_size\n",
    "        self.data_paths = data_paths\n",
    "        self.dataset_dir = Path(task)\n",
    "        self.subjects = None\n",
    "        self.test_subjects = None\n",
    "        self.preprocess = None\n",
    "        self.augment = None\n",
    "        self.transform = None\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "        self.include_preprocess = include_preprocess\n",
    "        self.include_augment = include_augment\n",
    "\n",
    "    def get_preprocessing_transform(self):\n",
    "        preprocess = tio.Compose([\n",
    "            tio.RescaleIntensity((-1, 1)),\n",
    "            tio.Resample((1,1,1)),\n",
    "            tio.EnsureShapeMultiple(8),\n",
    "            tio.Resize((10,10,10)),\n",
    "            tio.OneHot()\n",
    "        ])\n",
    "        return preprocess\n",
    "\n",
    "    def get_augmentation_transform(self):\n",
    "        augment = tio.Compose([\n",
    "                tio.RandomAffine(),\n",
    "                tio.RandomGamma(p=0.5),\n",
    "                tio.RandomNoise(p=0.5),\n",
    "                tio.RandomMotion(p=0.1),\n",
    "                tio.RandomBiasField(p=0.25),\n",
    "            ])\n",
    "        return augment\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "        self.preprocess = self.get_preprocessing_transform() if self.include_preprocess else None\n",
    "        self.augment = self.get_augmentation_transform() if self.include_augment else None\n",
    "        \n",
    "        if self.preprocess is not None and self.augment is not None:\n",
    "            self.transform = tio.Compose([self.preprocess, self.augment])\n",
    "        elif self.preprocess is None:\n",
    "            self.transform = self.augment\n",
    "        elif self.augment is None:\n",
    "            self.transform = self.preprocess\n",
    "        \n",
    "        print(self.transform, self.preprocess)\n",
    "        self.train_set = MRIDataset(self.data_paths['train_dir'], transform=self.transform)\n",
    "        self.test_set = MRIDataset(self.data_paths['test_dir'], transform=self.preprocess)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, self.batch_size, num_workers=12)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, self.batch_size, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cd9f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "data = MRIDataModule(\n",
    "    task='TestMonai',\n",
    "    batch_size= batch_size,\n",
    "    data_paths = {'train_dir': \"../../\" + CONFIG['TRAIN_LABELS_DIR'],\n",
    "                 'test_dir': \"../../\" + CONFIG['TEST_LABELS_DIR']},\n",
    "    include_preprocess = False,\n",
    "    include_augment = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d3ab703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n",
      "Training:   1114\n",
      "Test:       263\n"
     ]
    }
   ],
   "source": [
    "data.prepare_data()\n",
    "data.setup()\n",
    "print('Training:  ', len(data.train_set))\n",
    "print('Test:      ', len(data.test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bafddcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, net, criterion, learning_rate, optimizer_class):\n",
    "        super().__init__()\n",
    "        self.lr = learning_rate\n",
    "        self.net = net\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def prepare_batch(self, batch):\n",
    "        return batch['images'], batch['labels']\n",
    "\n",
    "    def infer_batch(self, batch):\n",
    "        x, y = self.prepare_batch(batch)\n",
    "        y_hat = self.net(x)\n",
    "        return y_hat, y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_hat, y = self.infer_batch(batch)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7975f8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "unet = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(8, 16, 32, 64),\n",
    "    strides=(1, 1, 1),\n",
    ")\n",
    "\n",
    "\"\"\"model = Model(\n",
    "    net=unet,\n",
    "    criterion=monai.losses.DiceCELoss(softmax=True, to_onehot_y=True),\n",
    "    learning_rate=1e-2,\n",
    "    optimizer_class=torch.optim.AdamW,\n",
    ")\"\"\"\n",
    "\n",
    "early_stopping = pl.callbacks.early_stopping.EarlyStopping(\n",
    "    monitor='train_loss',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = 10,\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.logger._default_hp_metric = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aaec29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Convolution(\n",
      "    (conv): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (adn): ADN(\n",
      "      (A): PReLU(num_parameters=1)\n",
      "      (D): Dropout(p=0.1, inplace=False)\n",
      "      (N): InstanceNorm3d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2250000, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=32, out_features=3, bias=True)\n",
      "    (6): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv = monai.networks.blocks.Convolution(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=batch_size,\n",
    "    adn_ordering=\"ADN\",\n",
    "    act=(\"prelu\", {\"init\": 0.2}),\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "conv_test = torch.nn.Sequential(        # Shapes\n",
    "    nn.Conv3d(1, 32, 3),    # 32 x sr\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "densenet = monai.networks.nets.DenseNet(\n",
    "    spatial_dims = 3, \n",
    "    in_channels = 1, \n",
    "    out_channels = 1,      \n",
    ")\n",
    "\n",
    "cnn_to_mlp = nn.Sequential(\n",
    "  nn.Flatten(1, -1),\n",
    "  nn.Linear(batch_size*150*150*100 , 64),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(64, 32),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(32, 3),  \n",
    "  nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "model = nn.Sequential(\n",
    "    conv,\n",
    "    cnn_to_mlp\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "model = Model(\n",
    "    net=model,\n",
    "    criterion= nn.functional.cross_entropy,\n",
    "    learning_rate=0.001,\n",
    "    optimizer_class=torch.optim.AdamW,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00261884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at 2022-04-19 13:03:57.265310\n",
      "None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 144 M \n",
      "------------------------------------\n",
      "144 M     Trainable params\n",
      "0         Non-trainable params\n",
      "144 M     Total params\n",
      "288.005   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831170ccc9044b2e9ed65e0ba79a6f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1141, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 550.00 MiB (GPU 0; 4.00 GiB total capacity; 2.71 GiB already allocated; 0 bytes free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining started at\u001b[39m\u001b[38;5;124m'\u001b[39m, start)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining duration:\u001b[39m\u001b[38;5;124m'\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:768\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 768\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:809\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    805\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[0;32m    807\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    808\u001b[0m )\n\u001b[1;32m--> 809\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1234\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1236\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1321\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1351\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:269\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(\n\u001b[0;32m    266\u001b[0m     dataloader, batch_to_device\u001b[38;5;241m=\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_to_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataloader_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    267\u001b[0m )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:208\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 208\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\batch\\training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m     87\u001b[0m     optimizers \u001b[38;5;241m=\u001b[39m _get_active_optimizers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizer_frequencies, batch_idx)\n\u001b[1;32m---> 88\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_loop\u001b[38;5;241m.\u001b[39mrun(split_batch, batch_idx)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:203\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[1;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madvance\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_progress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;66;03m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;66;03m# would be skipped otherwise\u001b[39;00m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_idx] \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39masdict()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:256\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[1;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[0;32m    249\u001b[0m         closure()\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:369\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_tpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTPUAccelerator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_native_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamp_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAMPType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNATIVE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_lbfgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_lbfgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1593\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1590\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1593\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1595\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1596\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py:1625\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[0;32m   1544\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1545\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1552\u001b[0m     using_lbfgs: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1553\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;124;03m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    each optimizer.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1623\u001b[0m \n\u001b[0;32m   1624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1625\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:168\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_idx, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:193\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"Performs the actual optimizer step.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    **kwargs: Any extra arguments to ``optimizer.step``\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(model, optimizer, opt_idx, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\native_amp.py:93\u001b[0m, in \u001b[0;36mNativeMixedPrecisionPlugin.optimizer_step\u001b[1;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# in manual optimization, the closure does not return a value\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skipped_backward:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# note: the scaler will skip the `optimizer.step` if nonfinite gradients are found\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(optimizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 338\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    340\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:285\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m--> 285\u001b[0m     retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py:137\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[0;32m    135\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 137\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py:139\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m    137\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias_correction2\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    141\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[0;32m    143\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 550.00 MiB (GPU 0; 4.00 GiB total capacity; 2.71 GiB already allocated; 0 bytes free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print('Training started at', start)\n",
    "trainer.fit(model=model, datamodule=data)\n",
    "print('Training duration:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a453f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\anaconda3\\lib\\site-packages\\monai\\visualize\\class_activation_maps.py:93: UserWarning: Not all target_layers exist in the network module: targets: ('layer4',).\n",
      "  warnings.warn(f\"Not all target_layers exist in the network module: targets: {self.target_layers}.\")\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmonai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CAM\n\u001b[0;32m      3\u001b[0m cam \u001b[38;5;241m=\u001b[39m CAM(nn_module\u001b[38;5;241m=\u001b[39mmodel, target_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer4\u001b[39m\u001b[38;5;124m\"\u001b[39m, fc_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_linear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\monai\\visualize\\class_activation_maps.py:313\u001b[0m, in \u001b[0;36mCAM.__call__\u001b[1;34m(self, x, class_idx, layer_idx)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, class_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, layer_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m    Compute the activation map with upsampling and postprocessing.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m        activation maps\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m     acti_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upsample_and_post_process(acti_map, x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\monai\\visualize\\class_activation_maps.py:290\u001b[0m, in \u001b[0;36mCAM.compute_map\u001b[1;34m(self, x, class_idx, layer_idx)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, class_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, layer_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 290\u001b[0m     logits, acti, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m     acti \u001b[38;5;241m=\u001b[39m acti[layer_idx]\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m class_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\monai\\visualize\\class_activation_maps.py:131\u001b[0m, in \u001b[0;36mModelWithHooks.__call__\u001b[1;34m(self, x, class_idx, retain_graph)\u001b[0m\n\u001b[0;32m    129\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m--> 131\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_idx \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m class_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m class_idx\n\u001b[0;32m    133\u001b[0m acti, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py:566\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;124;03m    Same as :meth:`torch.nn.Module.forward()`.\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m        Your model's output\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from monai.visualize import CAM\n",
    "\n",
    "cam = CAM(nn_module=model, target_layers=\"layer4\", fc_layers=\"last_linear\")\n",
    "result = cam(x=torch.rand((2, 3, 48, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6438d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalarImage(shape: (1, 256, 256, 180); spacing: (0.94, 0.94, 1.21); orientation: IPL+; path: \"..\\..\\data\\raw\\flattened\\ADNI_021_S_0231_MR_MPR__GradWarp__N3__Scaled_Br_20070816120042598_S28705_I67969.nii\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ScalarImage(shape: (1, 10, 10, 10); spacing: (24.80, 24.80, 22.40); orientation: IPL+; dtype: torch.FloatTensor; memory: 3.9 KiB)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tio.ScalarImage(data.train_set.df.iloc[647].filename)\n",
    "print(img)\n",
    "transform = data.get_preprocessing_transform()\n",
    "\n",
    "img = transform(img)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac753155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([817.,   0.,   0.,   0.,   0., 513.,   0.,   0.,   0., 368.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.train_set.df.Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b138e4",
   "metadata": {},
   "source": [
    "## Normal Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3257db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (256, 256, 166)\n",
      "affine: \n",
      "[[ 3.22026613e-08  2.45020353e-04 -1.20652326e+00  1.01537003e+02]\n",
      " [-2.46155907e-04 -9.36463053e-01 -3.15680094e-04  1.59494995e+02]\n",
      " [-9.40813092e-01  2.45017764e-04  4.12975332e-08  1.29677994e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='>'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b'027_S_0307'\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 256 256 166   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.        0.9408131 0.9364631 1.2065233 1.        1.        1.\n",
      " 1.       ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 2816\n",
      "glmin           : 0\n",
      "descrip         : b'MPR; GradWarp; B1 Correction; N3; Scaled'\n",
      "aux_file        : b'none'\n",
      "qform_code      : scanner\n",
      "sform_code      : unknown\n",
      "quatern_b       : 0.70710677\n",
      "quatern_c       : 9.77589e-10\n",
      "quatern_d       : -0.70710677\n",
      "qoffset_x       : 101.537\n",
      "qoffset_y       : 159.495\n",
      "qoffset_z       : 129.678\n",
      "srow_x          : [0. 0. 0. 0.]\n",
      "srow_y          : [0. 0. 0. 0.]\n",
      "srow_z          : [0. 0. 0. 0.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3555940ec68b468f8c8dda1a4e9fab8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=255), IntSlider(value=0, description='j', max=25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_slices(img_data):\n",
    "    paramtools = {\n",
    "        'i': IntSlider(min=0, max=img_data.shape[0]-1, step=1),\n",
    "        'j': IntSlider(min=0, max=img_data.shape[1]-1, step=1),\n",
    "        'k': IntSlider(min=0, max=img_data.shape[2]-1, step=1),\n",
    "    }\n",
    "    \n",
    "    @interact(**paramtools)\n",
    "    def show_interactive(i, j, k):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(25,25))\n",
    "        axes[0].imshow(img_data[i,:,:].T, cmap=\"magma\", origin=\"lower\")\n",
    "        axes[1].imshow(img_data[:,j,:].T, cmap=\"magma\", origin=\"lower\")\n",
    "        axes[2].imshow(img_data[:,:,k].T, cmap=\"magma\", origin=\"lower\")\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "#img = tio.ScalarImage(data.train_set.df.iloc[648].filename)\n",
    "img = nib.load(data.train_set.df.iloc[647].filename)\n",
    "#img.data = img.data.to(torch.int64)\n",
    "print(img)\n",
    "#transform = data.get_preprocessing_transform()\n",
    "\n",
    "#img = transform(img)\n",
    "\n",
    "show_slices(img.get_fdata())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465ce6d",
   "metadata": {},
   "source": [
    "## Broken Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4488d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/raw/flattened\\ADNI_021_S_0141_MR_MPR__GradWarp__N3__Scaled_Br_20061217092830688_S11036_I33396.nii\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be635833d604b9a960bfe359065461e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=255), IntSlider(value=0, description='j', max=25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#img = tio.ScalarImage(data.train_set.df.iloc[648].filename)\n",
    "print(data.train_set.df.iloc[648].filename)\n",
    "img = nib.load(data.train_set.df.iloc[648].filename)\n",
    "#img.data = img.data.to(torch.int64)\n",
    "print(type(img))\n",
    "#transform = data.get_preprocessing_transform()\n",
    "\n",
    "#img = transform(img)\n",
    "\n",
    "show_slices(img.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "050730c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/raw/flattened\\ADNI_010_S_0067_MR_MPR-R____N3__Scaled_Br_20070807151408143_S17808_I65577.nii\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (256, 256, 170)\n",
      "affine: \n",
      "[[ 5.65740103e-08  5.01775928e-07 -1.20481300e+00  1.00159691e+02]\n",
      " [-2.08552309e-01 -9.13322776e-01 -6.45603180e-07  1.61614151e+02]\n",
      " [-9.21817228e-01  2.06630521e-01  7.21194275e-08  8.43791885e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='>'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b'010_S_0067'\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 256 256 170   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.        0.9451143 0.9364052 1.204813  1.        1.        1.\n",
      " 1.       ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 1156\n",
      "glmin           : 0\n",
      "descrip         : b'MPR-R; ; N3; Scaled'\n",
      "aux_file        : b'none'\n",
      "qform_code      : scanner\n",
      "sform_code      : unknown\n",
      "quatern_b       : 0.7027357\n",
      "quatern_c       : -0.07850143\n",
      "quatern_d       : -0.7027357\n",
      "qoffset_x       : 100.15969\n",
      "qoffset_y       : 161.61415\n",
      "qoffset_z       : 84.37919\n",
      "srow_x          : [0. 0. 0. 0.]\n",
      "srow_y          : [0. 0. 0. 0.]\n",
      "srow_z          : [0. 0. 0. 0.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e32f598e7642d59fc1346d9dfcaa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=255), IntSlider(value=0, description='j', max=25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#img = tio.ScalarImage(data.train_set.df.iloc[648].filename)\n",
    "print(data.train_set.df.iloc[1433].filename)\n",
    "img = nib.load(data.train_set.df.iloc[1433].filename)\n",
    "#img.data = img.data.to(torch.int64)\n",
    "print(img)\n",
    "#transform = data.get_preprocessing_transform()\n",
    "\n",
    "#img = transform(img)\n",
    "\n",
    "show_slices(img.get_fdata())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
